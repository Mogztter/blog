{:title  "Load balancing: ECMP, IPVS, HAproxy"
 :layout :post
 :tags   ["devops"]}

Il y a un peu plus d'un an, https://vincent.bernat.ch/fr[Vincent Bernat] publiait un excellent article sur le load balancing appelé https://vincent.bernat.ch/fr/blog/2018-repartiteur-charge-multi-niveaux[Répartiteur de charge à multiples niveaux avec Linux]. Dans cet article, je réimplémenterai la solution proposée dans cet article et montrerai via des tests qu'elle fonctionne comme prévue

Pour une bonne compréhension, Il est conseillé de lire l'article présenté précédemment avant de commencer la lecture de ce qui suit.

== L'architecture générale

- Schema global:

- ECMP
- IPVS
- HAproxy
- Backend

Cloud Exoscale.
Installation manuelle.

== Niveau 1: ECMP

=== Introduction

Le premier étage de notre architecture est le routage ECMP. Ce dernier permet d'avoir une redondance sur le routage vers une IP montant être montée sur différentes machines.

Lorsque plusieurs routes sont configurées pour une même destination dans un routeur, ce dernier va devoir "choisir" où transmettre les paquets réseaux. +
Il existe plusieurs algorithmes de hashing pour ECMP. Le choix de l'argorithme est important, car pour des protocoles connectés comme TCP, on ne veut évidemment pas que les paquets d'une même connexion soient envoyées à différentes destinations.

Un algorithme de hashing intéressant (et utilisé chez Exoscale) est le `5-tuples`. Le choix de la destination se fera sur plusieurs critères:

- L'adresse source.
- L'adresse de destination.
- Le protocole.
- Le port source.
- Le port de destination.

Cet algorithme a l'avantage de répartir de façon très équitable les connexions vers les destinations.

<schema>

=== Mise en place

Nous commençons par créer une Elastic IP:

```shell
exo -A prod eip create ch-gva-2 --healthcheck-mode tcp --healthcheck-port 8080 --healthcheck-strikes-ok 1
┼──────────┼────────────────┼──────────────────────────────────────┼
│   ZONE   │       IP       │                  ID                  │
┼──────────┼────────────────┼──────────────────────────────────────┼
│ ch-gva-2 │ 89.145.167.130 │ f63d34e0-c797-49ce-89cd-fb695e3ffd6b │
┼──────────┼────────────────┼──────────────────────────────────────┼
```

Chez Exoscale, il est possible https://www.exoscale.com/syslog/releasing-managed-elastic-ip/[depuis peu] de configurer des healthchecks à réaliser lors de la création d'une Elastic IP. Le check sera réalisé sur le ou les machines sur lesquels l'Elastic IP est attachée, et cette dernière sera automatiquement détachée (et donc enlevée du pool ECMP) si le check est en erreur. +
Ici, je configure un check TCP sur le port 8080.

Mettons maintenant cette IP de côté, nous l'utiliserons plus tard.

== Création d'un réseau privé

=== Mise en place

```shell
$ exo -A prod privnet create --zone ch-gva-2 --description "load balancing article" "my_private_network"
┼────────────────────┼────────────────────────┼──────────────────────────────────────┼──────┼
│        NAME        │      DESCRIPTION       │                  ID                  │ DHCP │
┼────────────────────┼────────────────────────┼──────────────────────────────────────┼──────┼
│ my_private_network │ load balancing article │ 9b866d82-ace8-4a73-a266-b423697f8a37 │ n/a  │
┼────────────────────┼────────────────────────┼──────────────────────────────────────┼──────┼
```

== Niveau 4: Backends Python

Nous allons démarrer sur deux machines des serveurs HTTP Python tout simples, qui exposeront quelques fichiers. Dans une "vraie" architecture, ces serveurs seraient les serveurs HTTP exposant vos applications.

=== Mise en place

Créez ces deux machines, et ajoutez les dans votre réseau privé:

```shell
$ exo -A prod vm create --zone ch-gva-2 --privnet "my_private_network" --service-offering micro --template "Linux Debian 9 64-bit" --keypair "perso" backend-python-1

Deploying "backend-python-1" ⠙                                                  done!

$ exo -A prod vm create --zone ch-gva-2 --privnet "my_private_network" --service-offering micro --template "Linux Debian 9 64-bit" --keypair "perso" backend-python-2

Deploying "backend-python-2" ⠇                                                  done!
```

Nous allons maintenant configurer deux IP statiques sur l'interface privée de nos deux machines.
Connectez-vous dessus via SSH, puis configurez les IP de vos interfaces. Le fichier à créer est `/etc/network/interfaces.d/01-privnet.cfg`:

```
# Machine backend-python-1
auto eth1
iface eth1 inet static
   address 10.3.3.1/24
```

```
# Machine backend-python-2
auto eth1
iface eth1 inet static
   address 10.3.3.2/24
```

Mettons là aussi ces machines de côté pour l'instant.

== Niveau 3: HAProxy

Nous allons maintenant installer et configurer deux serveurs sur lesquels tournera https://www.haproxy.com/[HAProxy]. Ces serveurs HAProxy feront chacun du load balancing sur les serveurs Python créés précédemment.

Nous allons dans un premier temps attacher l'Elastic IP créée précédemment à ces machines HAProxy, Nous aurons donc une architecture sans "Niveau 2" par rapport à l'architecture présentée au début, et donc ressemblant à ça:

Cela nous permettra de voir les problèmes de cette architecture, et l'utilité du "Niveau 2".

=== Mise en place

*Security groups*

Créez un security group et configurez le en ouvrant le port 8080:

```
exo firewall create http
# ouvre le port 8080 en ingress
exo firewall add http --port 8080
# ouvre tous les ports en egress
exo -A prod firewall add http --egress
```

*Machines HAProxy*

Créez de nouveau deux machines virtuelles. Ces machines démarreront avec le security group précédemment créé:

```shell

exo -A prod vm create --zone ch-gva-2 --privnet "my_private_network" --service-offering micro --template "Linux Debian 9 64-bit" --keypair "perso" haproxy-1 --security-group http
Deploying "haproxy-1" ⠴                                                         done!

exo -A prod vm create --zone ch-gva-2 --privnet "my_private_network" --service-offering micro --template "Linux Debian 9 64-bit" --keypair "perso" haproxy-2 --security-group http
```

Configurez ici aussi les deux IP statiques des machines comme précédemment (les fichiers de configuration sont identiques). Choisissez `10.3.3.3` pour la machine `haproxy-1`, et `10.3.3.4` pour la machine `haproxy-2`.

Il faut maintenant installer sur ces machines. La procédure est identique sur les deux machines. Nous installerons les packages depuis `https://haproxy.debian.net`:

```shell

apt-get update
apt-get install curl

curl https://haproxy.debian.net/bernat.debian.org.gpg | \
      apt-key add -
echo deb http://haproxy.debian.net stretch-backports-2.0 main | \
      tee /etc/apt/sources.list.d/haproxy.list

apt-get update
apt-get install haproxy=2.0.\*
```

Configurons maintenant HAProxy. Sur les deux instances, remplacez le fichier `/etc/haproxy/haproxy.cfg` par:

```
frontend front1
  bind :8080
  default_backend servers

backend servers
  balance roundrobin
  server backend1 10.3.3.1:8080
  server backend2 10.3.3.2:8080
```

Cette configuration est très sommaire (aucun healthcheck n'est configuré par exemple), mais suffisante pour cet article. Elle permet de distribuer les requêtes sur les deux serveurs Python définis précédemment. Redémarrez ensuite HAProxy avec `systemctl restart haproxy`.

*Elastic IPs*

Attachons maintenant notre Elastic IP créée précédemment à ces deux instances:

```
exo -A prod eip associate 89.145.167.130 haproxy-1
exo -A prod eip associate 89.145.167.130 haproxy-2
`

*Servers Python*

Reprenons nos deux serveurs Python créé précédemment. Sur chaque serveur, créez via `dd` un fichier et exposez le via HTTP:

```shell
mkdir /tmp/server
cd /tmp/server
# Le fichier fera un peu moins d'un GB, si vous avez une petite connexion,
# modifiez le paramètre count pour créer un fichier plus petit.
dd if=/dev/zero of=file1 count=1000000 bs=1024

# Exposez le fichier sur le port 8080
# Lancez le dans un tmux par exemple si vous voulez lancer ce process
# en background
python -m SimpleHTTPServer 8080
```

Vous devriez maintenant pouvoir télécharger ces fichiers (ou un fichier `index.html` exposé par Python) via par exemple wget:

```
wget 89.145.167.130:8080
wget 89.145.167.130:8080/file1
`

Lancez plusieurs fois ces requêtes (par exemple la première pour éviter de télécharger à chaque fois le fichier), et vous verrez dans les logs de `SimpleHTTPServer` que les requêtes sont réparties sur les deux serveurs Python !

== Premier problème

=== Suppression d'un serveur HAProxy

Lancez le téléchargement du gros fichier avec `wget 89.145.167.130:8080/file1`. Au même moment, stoppez (avec `exo vm stop haproxy-1` par exemple) le serveur HAProxy servant le fichier (vous pouvez soit essayer au hasard, soit en installant et lançant tcpdump (`apt-get install tcpdump` puis `tcpdump port 8080`).

Par exemple, en lançant `tcpdump`, je vois que la machine `haproxy-1` sert le fichier. Je stoppe cette machine. Immédiatement, mon téléchargement est bloqué:

```
file1                  25%[====>                  ] 253,29M  --.-KB/s    tps 17m 39s^
|```

== Niveau 2: IPVS

Pour pallier à ce problème, nous allons rajouter un niveau à notre architecture:



== Les tests












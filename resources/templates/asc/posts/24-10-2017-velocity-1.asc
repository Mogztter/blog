{:title  "Velocity Londres 2017: jour 1"
  :layout :post
  :tags   ["velocity" "conference"]}

J'étais à O'Reilly Velocity Londres les 19 et 20 Octobre 2017, et cet article résumera ma première journée de conférence.

Je ne parlerais pas forcément de tous les talks ou keynotes que j'ai vu, mais ceux qui furent selon moi les plus intéréssants.

== L'organisation de la conférence

Tout d'abord, bravo aux organisateurs !
La conférence est parfaitement organisée.
Elle se déroulait à l'hôtel Hilton Métropole, et on sent le professionnalisme.

Il y a de l'espace, les salles sont grandes, bien équipées, l'image et le son sont parfaits. Il y avait en tout 6 salles de conférences (donc 6 talks en parallèle), et les keynotes étaient réalisées dans une énorme salle (en fait 2 salles classiques rassemblées).

Il y avait également un grande salle contenant l'espace sponsor avec des stands. C'est aussi dans cette salle que l'on prenait le repas du midi notamment.

J'ai par contre trouvé les repas du midi assez moyen, mais bon ce n'est pas le plus important.

Concernant les sujets des talks et keynotes, c'est technique, assez spécialisé, et pile dans mon domaine. En même temps, une conférence qui titre `Build & maintain complex distributed systems`, ça ne pouvait que m'intéresser :)

== Keynotes

Après être arrivé assez tôt, avoir pris mon petit déjeuner (gratuit chaque matin de conférence) et participé à un speed networking (histoire de faire connaissance avec d'autres participants et de parler un peu Anglais), je m'installe confortablement pour les keynotes.

===  Cloud native: Security threat or opportunity?

Une Keynote intéressante fut celle de Liz Rice sur la sécurité des architectures dites "Cloud native", en gros vm/conteneurs/orchestrateurs...

Tout d'abord, Liz Rice nous explique qu'aujourd'hui, on le sait pas forcément où le code tourne.
On a des centaines de VM/serveurs, certaines applications sont composés de dizaines de microservices, et les containers et les orchestrateurs rajoutent une couche de complexité au dessus de tout ça.

La speakeuse expliquait aussi la différence entre "l'ancien temps" (ou le présent si vous travaillez pour un grand groupe Français ^^) où les serveurs étaient patchés et maintenus en vie sur de longues périodes, là ou aujourd'hui on va plutôt essayer de mettre en place des infrastructures immuables (en gros on pète et on reconstruit).

La sécurité doit être intégrée directement dans le pipeline de déploiement, avec par exemple des outils permettant de scanner les containers à la rechercher de vulnérabilités.

Par exemple, il faut scanner les containers pour voir les versions des produits déployés, vérifier que l'utilisateur lançant un process n'est pas root, vérifier l'isolation du container par rapport à l'host...

Concernant l'host, des OS spécialisés pour faire tourner des containers (CoreOS, RancherOS...) peuvent également être une solution. Je n'ai personnellement pas d'avis sur ces OS, le nes ayant jamais utilisé.

Bien sûr, les IDS traditionnels peuvent toujours être utilisés si besoin.

Concernant le réseau, là aussi il faut sécuriser les communications, que ce soit au niveau chiffrement, authentification, ou restrictions (j'évite que des services qui n'ont pas à discuter entre eux puissent le faire).

Enfin, des protections "au runtime" comme SELinux ou AppArmor ont été évoquées.
La présentation s'est finie sur une petite démo de la faille Shellshock où un serveur httpd pouvait exécuter du code arbitraire.

En conclusion, une keynote intéressante, mais un détail méritait d'être évoqué et ne l'a pas été selon moi. La meilleure sécurité, c'est quand même d'éviter toute cette complexité (microservices, orchestrateurs, règles réseaux ultra complexes...) si on en a pas besoin.
Ces architectures sont complexes, et je pense qu'il faut rester simple et comprendre ce que l'on fait plutôt que de plonger tête baissée dans les toutes dernières archis.
Rappelons une chose, tout le monde n'est pas Google/Amazon/Facebook...

===  Why an interactive picture is worth a thousand numbers ?


Peut être ma keynote préférée des deux jours, ça envoyait du lourd ! Sara-Jane Dunn travaille pour Microsoft Research, et nous expliquait ici l'importance des visualisations par rapport notamment à des chiffres bruts.

Aujourd'hui, on a de plus en plus de données, de logs... On calcule souvent des statistiques sur ces données, mais ces statistiques sont parfois trompeuses !

Deux jeux de données peuvent produire des statistiques (moyennes, médianes...) semblables alors que les données n'ont rien à voir.

De plus, on doit parfois partager ces données avec des collègues, pas forcément de notre domaine (par exemple avec des scientifiques en biologie alors que nous on est informaticien).

C'est là que les visualisations interviennent.
Pouvoir représenter, et explorer des données de façon graphique est devenu indispensable aujourd'hui.

La speakeuse, à l'aide de nombreux exemples, nous montrait comment des visualisations aident à résoudre des problèmes parfois très complexes. Les exemples venaient du monde de la biologie, où un chercheur a même avoué que sans l'outil de visualisation développé par la speakeuse, ces recherches n'auraient probablement pas abouties.
Les visualisations lui avaient permis de voir son problème sous un angle totalement différent.

La speakeuse présentait ensuite quelques techniques pour créer des visualisations pertinentes. Cette slide montre bien par exemple qu'une visualisation à base de formes/graphes est largement plus pertinente qu'une visualisation à base de couleurs.
L'intéractivité est aussi aujourd'hui la clé de visualisations pertinentes.

En conclusion, investissez du temps pour créer les outils permettant de visualiser vos données !

== Talks

=== Consumer-driven contract testing with Pact and Docker

Ce talk, donné par Harry Winser, expliquait les stratégies et les outils et process développés pour valider des API HTTP dans une architecture microservice.


Les problèmes pour les API HTTP sont toujours les mêmes. Comment gérer la montée de version d'un service ? Comment je m'assure que les clients d'une version antérieure sont toujours compatibles avec la nouvelle version ?

Une solution peut être les `consumer driven contracts`. On définit un contrat d'interface pour notre API. Cela permet aux équipes de travailler de manière indépendantes, et d'écrire des tests pour valider nos contrats.
Une phrase prononcée intéressante était `write your consumer first`.

Attention, ces contrats ne concernent que la partie API, et ne permet donc pas de vérifier la logique métier des applications.

Le speakeur utilisait dans son entreprise un format appelé Pact, Ce format permet de décrire une requête HTTP, et s'intègre facilement dans des pipelines de déploiements grâce à une intégration avec de nombreux langages/plateformes (comme par exemple la JVM).

Les contrats Pact sont stockés dans une base appelée `Pact brocker`. Quand une application est build, son artifact (commme par exemple son .jar pour une application Java) est poussée dans un Nexus ou autre, et les contrats Pact de cette application dans le broker.
Il est aussi important de stocker des stubs/mock de l'API, qui seront ensuite utilisés par la suite.

Dans l'intégration continue des consumers d'une API, on utilise les stubs de l'API et les fichiers Pact pour vérifier que l'API correspond bien à un ou des contrats Pact.
Par exemple, un client communiquant avec 3 API pourra tester si il valide le contrat Pact pour ces 3 services.

Il est aussi possible de tester différentes versions de l'API, pour voir si on garde une rétrocompatibilité en cas de montée de version par exemple.
Ensuite, le résultat de ces tests sont publiés pour être exploités.

Ce talk était intéressant. Je n'avais jamais entendu parler de Pact, le format et l'écosystème autour semble prometteur.

== Real-world consistency explained

Attention, on passe au meilleur talk des deux jours !

Ce talk, donné par Uwe Friedrichsen, parlait de systèmes distribués, de consensus, de niveaux d'isolations dans les base de données... Bref, d'un sujet super important mais malheureusement maitrisé par très peu de monde.
je consacrerais d'ailleurs un article sur ces sujets prochainement.

==== Le "passé"

Le speaker commence tout d'abord à parler du "passé" (les guillemets sont importante).

On a donc depuis longtemps des bases de données relationnelles, avec des propriétés ACID, Ces base de données fonctionnent très bien, il est facile de raisonner avec (ACID apporte sur le papier des propriétés fortes intéressantes).

Mais (car il y a toujours un mais), ACID != Serializability ! Des anomalies peuvent apparaitres, et les transactions ne sont pas si isolées qu'on peut le penser (d'où les différents niveaux d'isolations dans les bases de données: read commited, snapshot isolation, serializability...).

le problème du mode serializable dans une base de donnée est la grande perte de performance associée (il faut généralement locker complètement les tables pour avoir ce niveau d'isolation, ce qui diminue fortement les performances).

De plus, les configurations par défaut des bases de données n'activent pas la sérialization.
Ces configurations par défaut, couplé à une méconnaissance des différents niveaux d'isolations par les bases de données, peuvent causer de sérieux soucis (et difficilement détectables) en production.

En conclusion, ACID c'est cool mais cela ne veut pas dire sérializable, attention !

TODO définir ACID, serializability
TODO décrire pb ACID : read/write skew par exemple

==== Le "présent"


Cloud, NoSQL, microservices... On a maintenant des architectures distribués. Et cela DOIT vous inquiéter !



